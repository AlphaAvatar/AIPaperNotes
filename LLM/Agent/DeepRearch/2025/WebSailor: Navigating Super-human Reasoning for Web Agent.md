论文链接：https://arxiv.org/pdf/2507.02592

代码链接：https://github.com/Alibaba-NLP/WebAge

# 摘要

超越人类认知局限是 LLM 训练的关键目标。像 DeepResearch 这样的专有 Agent 系统，在极其复杂的信息搜索基准测试（例如 BrowseComp）上展现出了超越人类的能力，这在以前是难以企及的。我们认为，**它们的成功取决于开源模型所缺乏的一种复杂推理模式：在探索浩瀚信息时，系统地降低极端不确定性的能力**。基于这一洞见，我们推出了 **WebSailor**，这是一种旨在培养这一关键能力的完整后训练方法。我们的方法包括通过结构化采样和信息混淆、RFT 冷启动以及高效的 Agent 强化学习训练算法——重复采样策略优化 (Duplicating Sampling Policy Optimizati, DUPO)，来生成新的高不确定性任务。凭借这一集成流程，WebSailor 在复杂的信息搜索任务中的表现显著优于所有开源 Agent，与专有  Agent 的性能相媲美，并缩小了能力差距。

# 1.介绍

信息搜索是人类解决不确定性的基本驱动力，而互联网已经彻底改变了这一驱动力。然而，人类驾驭这片广阔数字世界的能力却受到认知局限的制约：有限的记忆、脆弱的注意力，以及无法同时进行多条探索路径。领先的专有 Agent 系统，例如 Deep Research，表明大语言模型 (LLM) Agent 可以超越这些人类局限。它们在 BrowseComp-en/zh 等复杂的网络基准测试中表现出的超凡性能，源于其复杂的推理能力——无论是内部推理还是工具介导的推理——能够系统地降低不确定性。

然而，将这些高级推理能力注入开源 Agent 仍是一个悬而未决的问题。如图 1 所示，现有的开源 LLM 和 Web Agent 在 BrowseComp-en 数据集上的准确率接近于零。**这种显著的性能差距源于当前的训练范式侧重于我们所谓的 1 级和 2 级任务：即不确定性较低（例如单次搜索）或具有清晰、结构化解决路径（例如标准多跳问答）的问题**。这些数据集无法让模型应对在复杂基准测试中占主导地位的 3 级挑战——这些场景要求在没有预定义解决方案路径的复杂信息环境中进行稳健的组合泛化。因此，模型无法开发出应对这些挑战所需的复杂、多步骤推理能力。

为了引出这些超越人类的推理模式，我们生成了具有高度且难以降低的内在不确定性的训练数据。我们的主要机制是从现实世界网站上随机游走生成的互联知识结构中采样子图。从组合泛化的角度来看，这些子图呈现了已知实体和关系的全新组合，迫使模型对此前未曾见过的组合进行推理，并使其超越简单的启发式方法。这一过程生成了各种各样复杂且难以预先定义的涌现结构，迫使模型开发出可能超越现有人类模式的推理过程。

我们利用精心设计的信息混淆技术进一步提升任务难度，这直接增加了初始模糊性。结构复杂性和信息模糊性的结合，使得任务需要极其复杂的推理。例如，我们生成的一些问题极具挑战性，即使是像 o3 这样强大的专有模型也需要调用多达 40 次工具才能得出解决方案，这凸显了我们极力降低不确定性的重要性。

获得 QA 数据后，一个关键挑战是获得具有完全推理过程的有监督数据。虽然强大的开源大型推理模型 (LRM)（例如 QwQ 和 DeepSeek-R1）可以解决一些复杂的问答系统，但它们原生的推理输出不适合直接微调。这些模型表现出高度程式化和冗长的思维过程，如果模仿，可能会限制受训 Agent 开发自身灵活探索性策略的能力。此外，在需要数十次工具调用的长周期 Web 任务中，其冗长的推理链很快就会淹没上下文窗口，导致性能下降和可读性下降。为了解决这个问题，我们提出了一种新的方法：我们利用这些开源 LRM 生成成功的行动观察轨迹，然后重建推理。通过为每个步骤推断简洁、以行动为导向的思维，我们创建了一个清晰有效的监督信号，该信号能够捕捉解决方案的逻辑，而不会继承与程式化或冗长相关的缺陷。

在训练流程优化方面，尽管近期研究建议跳过 SFT，但我们证明，对于处理此类复杂任务的 Web Agent 来说，适度的拒绝采样微调 (RFT) 冷启动是必不可少的。一方面，此类场景的强化学习 (RL) 奖赏极其稀疏，初始反馈通常接近于零。另一方面，我们的方法并不过度依赖蒸馏；只需 2000 多个高质量示例的极简冷启动即可证明其有效性。由于多轮推理和大量工具的使用，此类任务的强化学习 (RL) Agent 训练速度极其缓慢。为了解决这个问题，我们提出了 Duplicating Sampling Policy Optimizati (DUPO)，它结合了两种动态采样策略——一种在训练前，一种在训练期间——以提高有效性和效率。

我们的 WebSailor 模型系列（3B、7B、32B 和 72B）在 BrowseComp-en/zh 上的表现优于所有开源模型和 Agent 方法，并且当与浏览功能结合使用时，也超越了 Grok-3 和 DouBao 等专有 LRM，如图 1 所示。此外，我们发现基于复杂的、不确定性驱动的推理模式的后训练表现出向下兼容性，在 GAIA、XBench-DeepSearch 和 SimpleQA 等更简单的任务上取得了良好的性能。

# 2.Problem Definition

