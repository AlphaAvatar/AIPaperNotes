# AIPaperNotes
Record daily reading of papers and related reproduction results in Chinese.

For more notes, please follow the blog: https://nopsled.blog.csdn.net/

## Paper Catalog

### Embedding

- NV-EMBED [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/Embedding/2025/NV-EMBED%3A%20IMPROVED%20TECHNIQUES%20FOR%20TRAINING%20LLMS%20AS%20GENERALIST%20EMBEDDING%20MODELS.md)]

### Flow

- Flow Matching [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/Flow/2023/FLOW%20MATCHING%20FOR%20GENERATIVE%20MODELING.md)]

### LLM

- **Agent**: LLM-based Single/Multi Agent model/system
    - **DeepResearch**:
        - WebSailor [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Agent/DeepRearch/2025/WebSailor%3A%20Navigating%20Super-human%20Reasoning%20for%20Web%20Agent.md)]
        - WebWatcher [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Agent/DeepRearch/2025/WebWatcher%3A%20Breaking%20New%20Frontiers%20of%20Vision-Language%20Deep%20Research%20Agent.md)]
    - **Reflection**
        - Metacognitive Reuse [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Agent/Reflection/2025/Metacognitive%20Reuse%3A%20Turning%20Recurring%20LLM%20Reasoning%20Into%20Concise%20Behaviors.md)]

- **Base Model**: Large Language Model
    - **Zhipu AI**
        - GLM 4.5 [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Base%20Model/Zhipu%20AI/2025/GLM-4.5%3A%20Agentic%2C%20Reasoning%2C%20and%20Coding%20(ARC)%20Foundation%20Models.md)]
    - **OpenAI**
        - gpt-oss [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Base%20Model/OpenAI/2025/gpt-oss-120b%20%26%20gpt-oss-20b%20Model%20Card.md)]

- **Prompt**: Prompt Engineering
    - **Context Learning**
        - ACE

- **Omni**: LLM-based full modal model
    - Qwen2.5 - Omni [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Omni/2025/Qwen2.5-Omni%20Technical%20Report.md)]
    - M3 - Agent [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Omni/2025/Seeing%2C%20Listening%2C%20Remembering%2C%20and%20Reasoning%3A%20A%20Multimodal%20Agent%20with%20Long-Term%20Memory.md)]

- **Quantization**: Model Weight/Optimizer/Activation Compressing
    - COAT [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Quantization/2025/COAT%3A%20COMPRESSING%20OPTIMIZER%20STATES%20AND%20ACTIVATION%20FOR%20MEMORY-EFFICIENT%20FP8%20TRAINING.md)]

- **Reasoning**: Long CoT model
    - Deepseek - R1 [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Reasoning/2025/DeepSeek-R1%3A%20Incentivizing%20Reasoning%20Capability%20in%20LLMs%20via%20Reinforcement%20Learning.md)]

- **Speech**: Speech LLM
    - **ALM**: Audio LLM for auido Input
        - Audio Flamingo 3

- **Survey**
    - DeepRearch [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Survey/DeepRearch/2025/A%20Comprehensive%20Survey%20of%20Deep%20Research%3A%20Systems%2C%20Methodologies%2C%20and%20Applications.md)]

- **Training**: LLM Model Training:
    - FIM (fill-in-the-middle)
    - Multi-token Prediction (Meta) [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/Training/Multi-token%20Prediction/2025/Better%20%26%20Faster%20Large%20Language%20Models%20via%20Multi-token%20Prediction.md)]

- **VLM**: Model Weight/Optimizer/Activation Compressing
    - Qwen - VL [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/VLM/2023/Qwen-VL%3A%20A%20Versatile%20Vision-Language%20Model%20for%20Understanding%2C%20Localization%2C%20Text%20Reading%2C%20and%20Beyond.md)]
    - LLaVA [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/LLM/VLM/2023/Visual%20Instruction%20Tuning.md)]

### Visual Encoder

- **Language-Image Representation Learning**:
    - CLIP [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/Visual%20Encoder/Language%20Image%20Pretraining/2021/Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision.md)]
    - SigLIP [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/Visual%20Encoder/Language%20Image%20Pretraining/2023/Sigmoid%20Loss%20for%20Language%20Image%20Pre-Training.md)]
    - LIFT [[Link](https://github.com/AlphaAvatar/AIPaperNotes/blob/main/Visual%20Encoder/Language%20Image%20Pretraining/2025/Language-Image%20Alignment%20with%20Fixed%20Text%20Encoders.md)]
